{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-30T14:19:56.054846Z","iopub.execute_input":"2021-10-30T14:19:56.055213Z","iopub.status.idle":"2021-10-30T14:19:56.088281Z","shell.execute_reply.started":"2021-10-30T14:19:56.055120Z","shell.execute_reply":"2021-10-30T14:19:56.087651Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# all the necessary libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.model_selection as model_selection\nimport sklearn.preprocessing as pre\n\nfrom sklearn.feature_selection import mutual_info_classif, SelectKBest\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.datasets import make_classification\n\n#models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:56.089750Z","iopub.execute_input":"2021-10-30T14:19:56.090092Z","iopub.status.idle":"2021-10-30T14:19:57.734775Z","shell.execute_reply.started":"2021-10-30T14:19:56.090060Z","shell.execute_reply":"2021-10-30T14:19:57.733828Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 1. Importing Data","metadata":{}},{"cell_type":"code","source":"main_df = pd.read_csv(r'/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv', index_col='sl_no')\nprint(f'Shape : {main_df.shape}')\nmain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.736671Z","iopub.execute_input":"2021-10-30T14:19:57.737322Z","iopub.status.idle":"2021-10-30T14:19:57.795420Z","shell.execute_reply.started":"2021-10-30T14:19:57.737270Z","shell.execute_reply":"2021-10-30T14:19:57.794751Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# to have a look at the general overview of the entire data\nmain_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.796971Z","iopub.execute_input":"2021-10-30T14:19:57.797339Z","iopub.status.idle":"2021-10-30T14:19:57.813244Z","shell.execute_reply.started":"2021-10-30T14:19:57.797308Z","shell.execute_reply":"2021-10-30T14:19:57.812590Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# to get the exact number of missing values in the column.\nmain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.814707Z","iopub.execute_input":"2021-10-30T14:19:57.815182Z","iopub.status.idle":"2021-10-30T14:19:57.827500Z","shell.execute_reply.started":"2021-10-30T14:19:57.815148Z","shell.execute_reply":"2021-10-30T14:19:57.826702Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# check if the status is no places\nmain_df['status'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.828805Z","iopub.execute_input":"2021-10-30T14:19:57.829632Z","iopub.status.idle":"2021-10-30T14:19:57.837475Z","shell.execute_reply.started":"2021-10-30T14:19:57.829595Z","shell.execute_reply":"2021-10-30T14:19:57.836817Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Does all the rows with missing values have a status of Not Placed?\n\nstatus_df = main_df[main_df['status']=='Not Placed']\nprint('Shape of the dataframe:',status_df.shape, sep ='\\n', end ='\\n\\n')\nprint('Number of rows with status as Not Placed:',status_df['status'].value_counts(), sep ='\\n', end ='\\n\\n')\nprint('Number of rows with salary as zero:',status_df['salary'].isnull().sum(), sep ='\\n', end ='\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.838728Z","iopub.execute_input":"2021-10-30T14:19:57.839302Z","iopub.status.idle":"2021-10-30T14:19:57.852888Z","shell.execute_reply.started":"2021-10-30T14:19:57.839264Z","shell.execute_reply":"2021-10-30T14:19:57.852180Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Insights:\n- We see that all rows with Status as 'Not Placed' have the salary as 'Nan', which is logical.\n- **Recomended change:**\n    - Drop the Salary column as using that we can predict the Placed status with an if statment.\n> If the value is not Nan then the person is placed or else he is not.\nIn real life we won't have such a column telling us these things.","metadata":{}},{"cell_type":"code","source":"# segrigating all the numeric and categorical columns\nnum_cols = list(main_df.select_dtypes(exclude=['object']).columns)\ncat_cols = list(main_df.select_dtypes(include=['object']).columns)\nprint('all the numeric cols: ',num_cols, end ='\\n\\n')\nprint('all the categorical cols:',cat_cols, end ='\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.854562Z","iopub.execute_input":"2021-10-30T14:19:57.854831Z","iopub.status.idle":"2021-10-30T14:19:57.865865Z","shell.execute_reply.started":"2021-10-30T14:19:57.854800Z","shell.execute_reply":"2021-10-30T14:19:57.863931Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"main_df[num_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.869260Z","iopub.execute_input":"2021-10-30T14:19:57.870272Z","iopub.status.idle":"2021-10-30T14:19:57.908094Z","shell.execute_reply.started":"2021-10-30T14:19:57.870212Z","shell.execute_reply":"2021-10-30T14:19:57.906995Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"main_df[cat_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.909465Z","iopub.execute_input":"2021-10-30T14:19:57.910160Z","iopub.status.idle":"2021-10-30T14:19:57.942321Z","shell.execute_reply.started":"2021-10-30T14:19:57.910073Z","shell.execute_reply":"2021-10-30T14:19:57.941490Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Visualisation","metadata":{}},{"cell_type":"code","source":"sns.pairplot(main_df[num_cols])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:57.943529Z","iopub.execute_input":"2021-10-30T14:19:57.943922Z","iopub.status.idle":"2021-10-30T14:20:04.908642Z","shell.execute_reply.started":"2021-10-30T14:19:57.943881Z","shell.execute_reply":"2021-10-30T14:20:04.907824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### Insights:\n- ***hsc_p*** and ***ssc_p*** have a high correlation: ***0.51***\n- ***degree_p*** and ***ssc_p*** have a high correlation: ***0.54***\n- ***hsc_p*** and ***degree_p*** have a high correlation: ***0.43***\n- ***mba_p*** and ***ssc_p*** have a high correlation: ***0.39***\n\n> Removing ***hsc_p***, ***degree_p*** and ***mba_p*** and keeping ***ssc_p***, would be a good choice as ***ssc_p explains the other 2 columns as well.***","metadata":{}},{"cell_type":"code","source":"#Change the figure size\nplt.figure(figsize=[20, 20])\n\nfor i in range(len(cat_cols)):\n    plt.subplot(4, 4, i+1)\n    if(i<7):\n        sns.countplot(x = main_df[cat_cols[i]], hue = main_df['status'])\n    else:\n        sns.countplot(x = main_df[cat_cols[i]])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:04.910331Z","iopub.execute_input":"2021-10-30T14:20:04.910823Z","iopub.status.idle":"2021-10-30T14:20:05.925571Z","shell.execute_reply.started":"2021-10-30T14:20:04.910776Z","shell.execute_reply":"2021-10-30T14:20:05.924786Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Change the figure size\nplt.figure(figsize=[20, 20])\n\nfor i in range(len(num_cols)):\n    plt.subplot(3, 3, i+1)\n    sns.violinplot(x = main_df[num_cols[i]], hue = main_df['status'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:05.926831Z","iopub.execute_input":"2021-10-30T14:20:05.927039Z","iopub.status.idle":"2021-10-30T14:20:06.828518Z","shell.execute_reply.started":"2021-10-30T14:20:05.927011Z","shell.execute_reply":"2021-10-30T14:20:06.827660Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Insights:\n- All the columns seem to be normaly disributed except the salary column.\n- No outlier treatment required as we are going to drop the salary column as it is.","metadata":{}},{"cell_type":"markdown","source":"# 3. Data Transformation","metadata":{}},{"cell_type":"code","source":"transform_df_1 = main_df.drop(['salary'], axis=1)\ntransform_df_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.829649Z","iopub.execute_input":"2021-10-30T14:20:06.829912Z","iopub.status.idle":"2021-10-30T14:20:06.851773Z","shell.execute_reply.started":"2021-10-30T14:20:06.829880Z","shell.execute_reply":"2021-10-30T14:20:06.850594Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Numeric to Categorical","metadata":{}},{"cell_type":"code","source":"num_cols.remove('salary')\nnum_cols","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.853531Z","iopub.execute_input":"2021-10-30T14:20:06.853990Z","iopub.status.idle":"2021-10-30T14:20:06.866395Z","shell.execute_reply.started":"2021-10-30T14:20:06.853938Z","shell.execute_reply":"2021-10-30T14:20:06.865755Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"transform_df_1[num_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.867621Z","iopub.execute_input":"2021-10-30T14:20:06.867947Z","iopub.status.idle":"2021-10-30T14:20:06.898208Z","shell.execute_reply.started":"2021-10-30T14:20:06.867909Z","shell.execute_reply":"2021-10-30T14:20:06.897346Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Insights:\n***Ranges***\n- ssc_p <code>[40.89 to 89.40]</code>\n- hsc_p <code>[37 to 97.7]</code>\n- degree_p <code>[50 to 91]</code>\n- etest_p <code>[50 to 98]</code>\n- mba_p <code>[51.21 to 77.89]</code>","metadata":{}},{"cell_type":"code","source":"def get_bins(df, col_name, bin_num):\n    lower = df[col_name].min()\n    upper = df[col_name].max()\n    bins = np.linspace(lower,upper,bin_num+1)\n    return bins\n\n# example :\nprint(get_bins(transform_df_1, 'ssc_p', 3))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.899497Z","iopub.execute_input":"2021-10-30T14:20:06.899718Z","iopub.status.idle":"2021-10-30T14:20:06.907066Z","shell.execute_reply.started":"2021-10-30T14:20:06.899690Z","shell.execute_reply":"2021-10-30T14:20:06.906338Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for i in (num_cols):\n    transform_df_1[i] = pd.cut(transform_df_1[i], bins=get_bins(transform_df_1, i, 2), labels=[0,1], include_lowest=True)\n    \nprint(transform_df_1[num_cols].info())\ntransform_df_1[num_cols].head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.908357Z","iopub.execute_input":"2021-10-30T14:20:06.908589Z","iopub.status.idle":"2021-10-30T14:20:06.953119Z","shell.execute_reply.started":"2021-10-30T14:20:06.908560Z","shell.execute_reply":"2021-10-30T14:20:06.952230Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# converting the categorical columns to integer columns\nfor i in num_cols:\n    transform_df_1[i] = transform_df_1[i].astype(int)\ntransform_df_1[num_cols].info()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.954625Z","iopub.execute_input":"2021-10-30T14:20:06.955005Z","iopub.status.idle":"2021-10-30T14:20:06.974640Z","shell.execute_reply.started":"2021-10-30T14:20:06.954959Z","shell.execute_reply":"2021-10-30T14:20:06.973448Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Change the figure size\nplt.figure(figsize=[20, 20])\n\nfor i in range(len(num_cols)):\n    plt.subplot(3, 3, i+1)\n    if(i<7):\n        sns.countplot(x = transform_df_1[num_cols[i]], hue = transform_df_1['status'])\n    else:\n        sns.countplot(x = transform_df_1[num_cols[i]])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:06.976349Z","iopub.execute_input":"2021-10-30T14:20:06.976623Z","iopub.status.idle":"2021-10-30T14:20:07.666938Z","shell.execute_reply.started":"2021-10-30T14:20:06.976588Z","shell.execute_reply":"2021-10-30T14:20:07.666226Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Homework:\n- make insights for the above graph.","metadata":{}},{"cell_type":"markdown","source":"## 3.2 Label Encode the Categorical Columns","metadata":{}},{"cell_type":"code","source":"# converting the object type values into numeric\nlabelencoder = pre.LabelEncoder()\nfor i in cat_cols:\n    transform_df_1[i] = labelencoder.fit_transform(transform_df_1[i])\ntransform_df_1[cat_cols].head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:07.668518Z","iopub.execute_input":"2021-10-30T14:20:07.668732Z","iopub.status.idle":"2021-10-30T14:20:07.686674Z","shell.execute_reply.started":"2021-10-30T14:20:07.668703Z","shell.execute_reply":"2021-10-30T14:20:07.685640Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Feature Selection\nref : ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[20, 5])\nsns.heatmap(transform_df_1.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:07.687967Z","iopub.execute_input":"2021-10-30T14:20:07.688288Z","iopub.status.idle":"2021-10-30T14:20:08.850277Z","shell.execute_reply.started":"2021-10-30T14:20:07.688245Z","shell.execute_reply":"2021-10-30T14:20:08.849607Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# from sklearn.feature_selection import mutual_info_classif\nmutual_info = mutual_info_classif(transform_df_1.drop('status', axis =1),transform_df_1['status'])\nmutual_info","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:08.851296Z","iopub.execute_input":"2021-10-30T14:20:08.851841Z","iopub.status.idle":"2021-10-30T14:20:08.908950Z","shell.execute_reply.started":"2021-10-30T14:20:08.851805Z","shell.execute_reply":"2021-10-30T14:20:08.908183Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = transform_df_1.drop('status', axis=1).columns\nmutual_info.sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:08.912828Z","iopub.execute_input":"2021-10-30T14:20:08.913075Z","iopub.status.idle":"2021-10-30T14:20:08.922014Z","shell.execute_reply.started":"2021-10-30T14:20:08.913046Z","shell.execute_reply":"2021-10-30T14:20:08.921149Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Insights:\n- In this case we can take the columns that provide some info and drop the ones that don't\n- Generally we take the top n columns, n defines the number of columns that the user wants to take into cosideration. <code>(Generally 5 or 10)</code>","metadata":{}},{"cell_type":"code","source":"# select colums that have non-zero mutual information\nsel_cols=[]\nfor i in range(len(mutual_info)):\n    if(mutual_info[i]>0):\n        sel_cols.append(mutual_info.index[i])\nsel_cols.append('status')\nprint(sel_cols)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:08.923455Z","iopub.execute_input":"2021-10-30T14:20:08.923807Z","iopub.status.idle":"2021-10-30T14:20:08.937595Z","shell.execute_reply.started":"2021-10-30T14:20:08.923733Z","shell.execute_reply":"2021-10-30T14:20:08.936586Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"transform_df_2 = transform_df_1[sel_cols]\ntransform_df_2.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:08.939308Z","iopub.execute_input":"2021-10-30T14:20:08.939663Z","iopub.status.idle":"2021-10-30T14:20:08.958845Z","shell.execute_reply.started":"2021-10-30T14:20:08.939620Z","shell.execute_reply":"2021-10-30T14:20:08.957798Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# from sklearn.feature_selection import SelectKBest\ntransform_df_3 = transform_df_1\nsel_top5 = SelectKBest(mutual_info_classif, k=5)\nsel_top5.fit(transform_df_3.drop('status', axis = 1), transform_df_3['status'])\n\n# to see which are the top5 columns:\nlist(transform_df_3.drop('status', axis=1).columns[sel_top5.get_support()])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:08.960299Z","iopub.execute_input":"2021-10-30T14:20:08.961049Z","iopub.status.idle":"2021-10-30T14:20:09.018484Z","shell.execute_reply.started":"2021-10-30T14:20:08.961004Z","shell.execute_reply":"2021-10-30T14:20:09.017599Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sel_top5 = list(transform_df_3.drop('status', axis=1).columns[sel_top5.get_support()])\nsel_top5.append('status')\ntransform_df_3 = transform_df_3[sel_top5]\ntransform_df_3.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.019978Z","iopub.execute_input":"2021-10-30T14:20:09.020381Z","iopub.status.idle":"2021-10-30T14:20:09.036256Z","shell.execute_reply.started":"2021-10-30T14:20:09.020332Z","shell.execute_reply":"2021-10-30T14:20:09.034500Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"**NOTE**\n- transform_df_1 : all the columns\n- transform_df_2 : the columns with some mutual information\n- transform_df_3 : the top 5 columns with mutual information","metadata":{}},{"cell_type":"markdown","source":"# 4. Model Selection","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"#### transform_df_1","metadata":{}},{"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\nlog_r = LogisticRegression()\nX_train, X_test, y_train, y_test = model_selection.train_test_split(transform_df_1.drop('status', axis =1), \n                                                                    transform_df_1['status'],\n                                                                    test_size=0.2, random_state=42)\nlog_r.fit(X_train, y_train)\ny_pred = log_r.predict(X_test)\n\n# from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test , y_pred))\n\n# accuraccy of the model\nprint('Score for transform_df_1: {:.4f}'.format(accuracy_score(y_test , y_pred)))\nprint('Score: {:.4f}'.format(log_r.score(X_test,y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.038230Z","iopub.execute_input":"2021-10-30T14:20:09.038508Z","iopub.status.idle":"2021-10-30T14:20:09.065433Z","shell.execute_reply.started":"2021-10-30T14:20:09.038473Z","shell.execute_reply":"2021-10-30T14:20:09.064417Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test , y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.067060Z","iopub.execute_input":"2021-10-30T14:20:09.067396Z","iopub.status.idle":"2021-10-30T14:20:09.301538Z","shell.execute_reply.started":"2021-10-30T14:20:09.067350Z","shell.execute_reply":"2021-10-30T14:20:09.300769Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### transform_df_2","metadata":{}},{"cell_type":"code","source":"log_r = LogisticRegression()\nX_train, X_test, y_train, y_test = model_selection.train_test_split(transform_df_2.drop('status', axis =1), \n                                                                    transform_df_2['status'], test_size=0.25,\n                                                                    random_state=42)\nlog_r.fit(X_train, y_train)\ny_pred = log_r.predict(X_test)\n\nprint('Score for transform_df_1: {:.4f}'.format(accuracy_score(y_test , y_pred)))\nsns.heatmap(confusion_matrix(y_test , y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.302690Z","iopub.execute_input":"2021-10-30T14:20:09.302940Z","iopub.status.idle":"2021-10-30T14:20:09.558718Z","shell.execute_reply.started":"2021-10-30T14:20:09.302910Z","shell.execute_reply":"2021-10-30T14:20:09.557361Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"#### transform_df_3","metadata":{}},{"cell_type":"code","source":"log_r = LogisticRegression()\nX_train, X_test, y_train, y_test = model_selection.train_test_split(transform_df_2.drop('status', axis =1), \n                                                                    transform_df_2['status'], test_size=0.25,\n                                                                    random_state=42)\nlog_r.fit(X_train, y_train)\ny_pred = log_r.predict(X_test)\n\nprint('Score for transform_df_1: {:.4f}'.format(accuracy_score(y_test , y_pred)))\nsns.heatmap(confusion_matrix(y_test , y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.560402Z","iopub.execute_input":"2021-10-30T14:20:09.560761Z","iopub.status.idle":"2021-10-30T14:20:09.853611Z","shell.execute_reply.started":"2021-10-30T14:20:09.560698Z","shell.execute_reply":"2021-10-30T14:20:09.852794Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# how to get the TP, FP, FN, TN values from the confusion matrix.\na = confusion_matrix(y_test , y_pred)\nprint(a)\nprint(\"TP: \",a[0,0])\nprint(\"FN: \",a[1,0])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.855198Z","iopub.execute_input":"2021-10-30T14:20:09.855460Z","iopub.status.idle":"2021-10-30T14:20:09.863793Z","shell.execute_reply.started":"2021-10-30T14:20:09.855427Z","shell.execute_reply":"2021-10-30T14:20:09.862849Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Home Work:\n- find the precision,recall, f1-score for the above Confusion Matrix. \n- find the average accuracy for log_reg using the <code>average_accuracy()</code> method.","metadata":{}},{"cell_type":"code","source":"# code goes here.\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.865011Z","iopub.execute_input":"2021-10-30T14:20:09.865646Z","iopub.status.idle":"2021-10-30T14:20:09.877410Z","shell.execute_reply.started":"2021-10-30T14:20:09.865605Z","shell.execute_reply":"2021-10-30T14:20:09.876268Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Find the accuracy of the models using the average_accuracy method:\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.879073Z","iopub.execute_input":"2021-10-30T14:20:09.879497Z","iopub.status.idle":"2021-10-30T14:20:09.887856Z","shell.execute_reply.started":"2021-10-30T14:20:09.879452Z","shell.execute_reply":"2021-10-30T14:20:09.887039Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 KNN","metadata":{}},{"cell_type":"markdown","source":"#### transform_df_1","metadata":{}},{"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5,algorithm='brute')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.889147Z","iopub.execute_input":"2021-10-30T14:20:09.890306Z","iopub.status.idle":"2021-10-30T14:20:09.900976Z","shell.execute_reply.started":"2021-10-30T14:20:09.890263Z","shell.execute_reply":"2021-10-30T14:20:09.899965Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(transform_df_1.drop('status', axis =1), \n                                                                    transform_df_1['status'], test_size=0.25, \n                                                                    random_state=42)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.902940Z","iopub.execute_input":"2021-10-30T14:20:09.903307Z","iopub.status.idle":"2021-10-30T14:20:09.922604Z","shell.execute_reply.started":"2021-10-30T14:20:09.903262Z","shell.execute_reply":"2021-10-30T14:20:09.921508Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import classification_report\n# from sklearn.metrics import accuracy_score\nprint(\"For classification report:\")\nprint(classification_report(y_test , y_pred))\naccuracy_score(y_test , y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.923916Z","iopub.execute_input":"2021-10-30T14:20:09.924487Z","iopub.status.idle":"2021-10-30T14:20:09.937698Z","shell.execute_reply.started":"2021-10-30T14:20:09.924444Z","shell.execute_reply":"2021-10-30T14:20:09.936977Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"#### transform_df_2","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(transform_df_2.drop('status', axis =1), \n                                                                    transform_df_2['status'], test_size=0.25, \n                                                                    random_state=42)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nprint(\"For classification report:\")\nprint(classification_report(y_test , y_pred))\naccuracy_score(y_test , y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.939400Z","iopub.execute_input":"2021-10-30T14:20:09.939823Z","iopub.status.idle":"2021-10-30T14:20:09.968590Z","shell.execute_reply.started":"2021-10-30T14:20:09.939781Z","shell.execute_reply":"2021-10-30T14:20:09.967823Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"#### transform_df_3","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(transform_df_3.drop('status', axis =1), \n                                                                    transform_df_3['status'], test_size=0.25, \n                                                                    random_state=42)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nprint(\"For classification report:\")\nprint(classification_report(y_test , y_pred))\naccuracy_score(y_test , y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.969913Z","iopub.execute_input":"2021-10-30T14:20:09.970297Z","iopub.status.idle":"2021-10-30T14:20:09.992684Z","shell.execute_reply.started":"2021-10-30T14:20:09.970250Z","shell.execute_reply":"2021-10-30T14:20:09.991786Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Insights: (Home work)\n- Given the same random state for the split and the same model being fit:\n    - transform_df_1 gives us as an accuracy of **81%** <code>f1-score: 0 -> 64 | 1 -> 88</code>\n    - transform_df_2 gives us as an accuracy of **__%** <code>f1-score: 0 -> __ | 1 -> __</code>\n    - transform_df_3 gives us as an accuracy of **__%** <code>f1-score: 0 -> __ | 1 -> __</code>\n- Use Stratified K Fold to have a better understanding of the same.","metadata":{}},{"cell_type":"markdown","source":"### Model Parameter Tuning","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\nparam = dict(n_neighbors=list(range(5,57,2)), algorithm=list(['brute','auto']))\nprint(param)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:09.994001Z","iopub.execute_input":"2021-10-30T14:20:09.994556Z","iopub.status.idle":"2021-10-30T14:20:10.000162Z","shell.execute_reply.started":"2021-10-30T14:20:09.994504Z","shell.execute_reply":"2021-10-30T14:20:09.999310Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"grid = GridSearchCV(knn, param, cv=10, scoring='f1')\nX = transform_df_1.drop('status',axis=1)\ny = transform_df_1['status']\n# fit the grid with data\ngrid.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:10.001324Z","iopub.execute_input":"2021-10-30T14:20:10.002262Z","iopub.status.idle":"2021-10-30T14:20:13.219836Z","shell.execute_reply.started":"2021-10-30T14:20:10.002212Z","shell.execute_reply":"2021-10-30T14:20:13.218904Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# examine the best model\n\n# Single best score achieved across all params (k)\nprint(grid.best_score_)\n\n# Dictionary containing the parameters (k) used to generate that score\nprint(grid.best_params_)\n\n# Actual model object fit with those best parameters\n# Shows default parameters that we did not specify\nprint(grid.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:13.220987Z","iopub.execute_input":"2021-10-30T14:20:13.221591Z","iopub.status.idle":"2021-10-30T14:20:13.228132Z","shell.execute_reply.started":"2021-10-30T14:20:13.221550Z","shell.execute_reply":"2021-10-30T14:20:13.227252Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold\ndef average_accuracy(df, model):\n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=12) \n    all_accuracy = []\n    \n    X = df.drop('status', axis = 1)\n    y = df['status']\n    \n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n        \n        model.fit(X_train, y_train) \n        all_accuracy.append(model.score(X_test, y_test))\n    all_accuracy = sum(all_accuracy)/len(all_accuracy)\n    return all_accuracy\n\nknn = KNeighborsClassifier(n_neighbors=43)\nprint('transform_df_1: {:.4f}'.format(average_accuracy(transform_df_1,knn)))\nprint('transform_df_2: {:.4f}'.format(average_accuracy(transform_df_2,knn)))\nprint('transform_df_3: {:.4f}'.format(average_accuracy(transform_df_3,knn)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:13.229807Z","iopub.execute_input":"2021-10-30T14:20:13.230103Z","iopub.status.idle":"2021-10-30T14:20:13.405712Z","shell.execute_reply.started":"2021-10-30T14:20:13.230061Z","shell.execute_reply":"2021-10-30T14:20:13.404819Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Naive Bayes","metadata":{}},{"cell_type":"code","source":"# from sklearn.naive_bayes import GaussianNB\nX = transform_df_1.drop('status', axis=1)\ny = transform_df_1['status']\nX_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=9) #Split the dataset\n\nnv = GaussianNB() # create a classifier\n\nnv.fit(X_train,y_train) # fitting the data\n\ny_pred = nv.predict(X_test) # store the prediction data\n\nprint(classification_report(y_test , y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:13.407181Z","iopub.execute_input":"2021-10-30T14:20:13.407791Z","iopub.status.idle":"2021-10-30T14:20:13.424487Z","shell.execute_reply.started":"2021-10-30T14:20:13.407724Z","shell.execute_reply":"2021-10-30T14:20:13.423801Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"X = transform_df_2.drop('status', axis=1)\ny = transform_df_2['status']\nX_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=9) #Split the dataset\n\nnv = GaussianNB() # create a classifier\n\nnv.fit(X_train,y_train) # fitting the data\n\ny_pred = nv.predict(X_test) # store the prediction data\n\nprint(classification_report(y_test , y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:13.426018Z","iopub.execute_input":"2021-10-30T14:20:13.426656Z","iopub.status.idle":"2021-10-30T14:20:13.444576Z","shell.execute_reply.started":"2021-10-30T14:20:13.426614Z","shell.execute_reply":"2021-10-30T14:20:13.443812Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"X = transform_df_3.drop('status', axis=1)\ny = transform_df_3['status']\nX_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=9) #Split the dataset\n\nnv = GaussianNB() # create a classifier\n\nnv.fit(X_train,y_train) # fitting the data\n\ny_pred = nv.predict(X_test) # store the prediction data\n\nprint(classification_report(y_test , y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:13.445931Z","iopub.execute_input":"2021-10-30T14:20:13.446323Z","iopub.status.idle":"2021-10-30T14:20:13.462911Z","shell.execute_reply.started":"2021-10-30T14:20:13.446286Z","shell.execute_reply":"2021-10-30T14:20:13.462192Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"nv = GaussianNB()\nprint('transform_df_1: {:.4f}'.format(average_accuracy(transform_df_1,nv)))\nprint('transform_df_2: {:.4f}'.format(average_accuracy(transform_df_2,nv)))\nprint('transform_df_3: {:.4f}'.format(average_accuracy(transform_df_3,nv)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:20:13.464078Z","iopub.execute_input":"2021-10-30T14:20:13.464889Z","iopub.status.idle":"2021-10-30T14:20:13.584723Z","shell.execute_reply.started":"2021-10-30T14:20:13.464852Z","shell.execute_reply":"2021-10-30T14:20:13.584131Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 SVM","metadata":{}},{"cell_type":"code","source":"# from sklearn.svm import SVC\nsvm = SVC(kernel='linear',class_weight={0:5, 1:5})\n\nX = transform_df_1.drop('status', axis=1)\ny = transform_df_1['status']\nX_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=42) #Split the dataset\n\nsvm.fit(X_train,y_train)\ny_pred = svm.predict(X_test) # store the prediction data\n\nprint(classification_report(y_test , y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:21:13.284802Z","iopub.execute_input":"2021-10-30T14:21:13.285488Z","iopub.status.idle":"2021-10-30T14:21:13.303411Z","shell.execute_reply.started":"2021-10-30T14:21:13.285443Z","shell.execute_reply":"2021-10-30T14:21:13.302315Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"param = {'kernel' : [ 'linear', 'poly', 'rbf', 'sigmoid'],\n         'class_weight' : [{0:6, 1:1},{0:5, 1:1},{0:4, 1:1},{0:3, 1:1},{0:2, 1:1}]}\n\nmodel = SVC()\nsearch = GridSearchCV(model, param, cv=10, scoring='f1')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:21:53.839825Z","iopub.execute_input":"2021-10-30T14:21:53.840147Z","iopub.status.idle":"2021-10-30T14:21:53.845601Z","shell.execute_reply.started":"2021-10-30T14:21:53.840100Z","shell.execute_reply":"2021-10-30T14:21:53.844682Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# execute search\nresult = search.fit(X, y)\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:21:56.803708Z","iopub.execute_input":"2021-10-30T14:21:56.804033Z","iopub.status.idle":"2021-10-30T14:21:58.091225Z","shell.execute_reply.started":"2021-10-30T14:21:56.803997Z","shell.execute_reply":"2021-10-30T14:21:58.090197Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"svm = SVC(class_weight = {0: 2, 1: 1}, kernel = 'linear')\nprint('transform_df_1: {:.4f}'.format(average_accuracy(transform_df_1,svm)))\nprint('transform_df_2: {:.4f}'.format(average_accuracy(transform_df_2,svm)))\nprint('transform_df_3: {:.4f}'.format(average_accuracy(transform_df_3,svm)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:22:14.889933Z","iopub.execute_input":"2021-10-30T14:22:14.890391Z","iopub.status.idle":"2021-10-30T14:22:15.031713Z","shell.execute_reply.started":"2021-10-30T14:22:14.890354Z","shell.execute_reply":"2021-10-30T14:22:15.031089Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## 4.5 Decision Trees","metadata":{}},{"cell_type":"code","source":"X = transform_df_3.drop('status', axis=1)\ny = transform_df_3['status']\nX_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=42) #Split the dataset\n\n# from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree = dtree.fit(X, y)\n\ny_pred = dtree.predict(X_test) # store the prediction data\n\nprint(classification_report(y_test , y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:35:01.471966Z","iopub.execute_input":"2021-10-30T14:35:01.472378Z","iopub.status.idle":"2021-10-30T14:35:01.493572Z","shell.execute_reply.started":"2021-10-30T14:35:01.472342Z","shell.execute_reply":"2021-10-30T14:35:01.492535Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"%%time\nparam = {'criterion' : [\"gini\", \"entropy\"],\n         'max_depth' : [5,10,15], \n         'class_weight' : [{0:6, 1:1},{0:5, 1:1},{0:4, 1:1},{0:3, 1:1},{0:2, 1:1}], \n         'min_samples_leaf' :[1,2,3]}\n\nmodel = DecisionTreeClassifier(random_state=42)\nsearch = GridSearchCV(model, param, cv=10, scoring='f1')\n\n# execute search\nresult = search.fit(X, y)\n# summarize result\nprint('Best Score: %s' % result.best_score_)\nprint('Best Hyperparameters: %s' % result.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:35:12.254697Z","iopub.execute_input":"2021-10-30T14:35:12.255295Z","iopub.status.idle":"2021-10-30T14:35:16.813369Z","shell.execute_reply.started":"2021-10-30T14:35:12.255256Z","shell.execute_reply":"2021-10-30T14:35:16.812448Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"dtree = DecisionTreeClassifier(class_weight = {0: 2, 1: 1}, criterion = 'gini',\n                               max_depth = 5, min_samples_leaf = 1)\nprint('transform_df_1: {:.4f}'.format(average_accuracy(transform_df_1,dtree)))\nprint('transform_df_2: {:.4f}'.format(average_accuracy(transform_df_2,dtree)))\nprint('transform_df_3: {:.4f}'.format(average_accuracy(transform_df_3,dtree)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:36:25.505611Z","iopub.execute_input":"2021-10-30T14:36:25.505930Z","iopub.status.idle":"2021-10-30T14:36:25.627844Z","shell.execute_reply.started":"2021-10-30T14:36:25.505895Z","shell.execute_reply":"2021-10-30T14:36:25.626921Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Testing for overfitting:\nX = transform_df_3.drop('status', axis=1)\ny = transform_df_3['status']\nX_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=42) #Split the dataset\n\n# from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(class_weight = {0: 2, 1: 1}, criterion = 'gini',\n                               max_depth = 3, min_samples_leaf = 1)\ndtree = dtree.fit(X, y)\n\nprint('Training Accuraccy: {:.4f}'.format(dtree.score(X_train, y_train)))\nprint('Testing Accuraccy: {:.4f}'.format(dtree.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:40:49.053716Z","iopub.execute_input":"2021-10-30T14:40:49.054590Z","iopub.status.idle":"2021-10-30T14:40:49.071325Z","shell.execute_reply.started":"2021-10-30T14:40:49.054540Z","shell.execute_reply":"2021-10-30T14:40:49.070316Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"# 5. Oversampling and Undersampling","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Over Sampling","metadata":{}},{"cell_type":"code","source":"# from imblearn.over_sampling import RandomOverSampler\n# from imblearn.under_sampling import RandomUnderSampler\n# from sklearn.datasets import make_classification\n\n# OverSampling and UnderSampling the transformdf_1\nX = transform_df_1.drop('status', axis =1)\ny = transform_df_1['status']\n\nprint('Before sampling:',pd.Series(y).value_counts(),end='\\n\\n',sep='\\n')\n# define dataset\nX, y = make_classification(n_samples=200, weights=[0.70], flip_y=0)\n\n# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority')\n\n# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)\n\nprint('After sampling:',pd.Series(y_over).value_counts(),sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:42:41.183805Z","iopub.execute_input":"2021-10-30T14:42:41.184722Z","iopub.status.idle":"2021-10-30T14:42:41.197416Z","shell.execute_reply.started":"2021-10-30T14:42:41.184647Z","shell.execute_reply":"2021-10-30T14:42:41.196551Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"def KFold_accuracy(X,y,model):\n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=12) \n    all_accuracy = []\n        \n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n        \n        model.fit(X_train, y_train) \n        all_accuracy.append(model.score(X_test, y_test))\n    all_accuracy = sum(all_accuracy)/len(all_accuracy)\n    return all_accuracy","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:46:01.629798Z","iopub.execute_input":"2021-10-30T14:46:01.630111Z","iopub.status.idle":"2021-10-30T14:46:01.637204Z","shell.execute_reply.started":"2021-10-30T14:46:01.630078Z","shell.execute_reply":"2021-10-30T14:46:01.636266Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression:\nlog_r = LogisticRegression()\nprint('Logistic Regression accuracy:{:.4f}'.format(KFold_accuracy(X_over,y_over, log_r)))\n\n# KNN:\nknn = KNeighborsClassifier(n_neighbors=43)\nprint('KNN accuracy:{:.4f}'.format(KFold_accuracy(X_over,y_over, knn)))\n\n# Naive Bayes:\nnv = GaussianNB()\nprint('Naive Bayes accuracy:{:.4f}'.format(KFold_accuracy(X_over,y_over, nv)))\n\n# SVM:\nsvm = SVC(class_weight = {0: 2, 1: 1}, kernel = 'rbf')\nprint('SVM accuracy:{:.4f}'.format(KFold_accuracy(X_over,y_over,svm)))\n\n# Decision Tree:\ndtree = DecisionTreeClassifier(class_weight = {0: 2, 1: 1}, criterion = 'gini',\n                               max_depth = 5, min_samples_leaf = 1)\n\nprint('Decision Tree accuracy: {:.4f}'.format(KFold_accuracy(X_over,y_over, dtree)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:47:07.244907Z","iopub.execute_input":"2021-10-30T14:47:07.245206Z","iopub.status.idle":"2021-10-30T14:47:07.408616Z","shell.execute_reply.started":"2021-10-30T14:47:07.245171Z","shell.execute_reply":"2021-10-30T14:47:07.407749Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Under Sampling:","metadata":{}},{"cell_type":"code","source":"# OverSampling and UnderSampling the transformdf_1\nX = transform_df_1.drop('status', axis =1)\ny = transform_df_1['status']\n\nprint('Before sampling:',X.shape,end='\\n\\n',sep='\\n')\n\n# define dataset\nX, y = make_classification(n_samples=200, weights=[0.30], flip_y=0)\n\n# define undersample strategy\nundersampling = RandomUnderSampler(sampling_strategy='majority')\n\n# fit and apply the transform\nX_under, y_under = undersampling.fit_resample(X, y)\n\nprint('After sampling:',X_over.shape,sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:52:28.409465Z","iopub.execute_input":"2021-10-30T14:52:28.410149Z","iopub.status.idle":"2021-10-30T14:52:28.419782Z","shell.execute_reply.started":"2021-10-30T14:52:28.410106Z","shell.execute_reply":"2021-10-30T14:52:28.419175Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression:\nlog_r = LogisticRegression()\nprint('Logistic Regression accuracy:{:.4f}'.format(KFold_accuracy(X_under,y_under, log_r)))\n\n# KNN:\nknn = KNeighborsClassifier(n_neighbors=43)\nprint('KNN accuracy:{:.4f}'.format(KFold_accuracy(X_under,y_under, knn)))\n\n# Naive Bayes:\nnv = GaussianNB()\nprint('Naive Bayes accuracy:{:.4f}'.format(KFold_accuracy(X_under,y_under, nv)))\n\n# SVM:\nsvm = SVC(class_weight = {0: 2, 1: 1}, kernel = 'rbf')\nprint('SVM accuracy:{:.4f}'.format(KFold_accuracy(X_under,y_under,svm)))\n\n# Decision Tree:\ndtree = DecisionTreeClassifier(class_weight = {0: 2, 1: 1}, criterion = 'gini',\n                               max_depth = 5, min_samples_leaf = 1)\n\nprint('Decision Tree accuracy: {:.4f}'.format(KFold_accuracy(X_under,y_under, dtree)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:51:28.850599Z","iopub.execute_input":"2021-10-30T14:51:28.850927Z","iopub.status.idle":"2021-10-30T14:51:28.976093Z","shell.execute_reply.started":"2021-10-30T14:51:28.850890Z","shell.execute_reply":"2021-10-30T14:51:28.974836Z"},"trusted":true},"execution_count":110,"outputs":[]}]}